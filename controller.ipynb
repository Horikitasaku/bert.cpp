{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert.cpp'...\n",
      "remote: Enumerating objects: 219, done.\u001b[K\n",
      "remote: Counting objects: 100% (219/219), done.\u001b[K\n",
      "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
      "remote: Total 219 (delta 126), reused 192 (delta 101), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (219/219), 154.78 KiB | 747.00 KiB/s, done.\n",
      "Resolving deltas: 100% (126/126), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ggerganov/ggml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$env:HTTPS_PROXY = \"http://proxy:port\" \n",
    "$env:https_proxy = \"http://proxy:port\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/bert.cpp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"http_proxy\"] = \"http://127.0.0.1:7891\"\n",
    "# os.environ[\"https_proxy\"] = \"http://127.0.0.1:7891\"\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"models/download-ggml.py\", line 35, in <module>\n",
      "    args.func(args)\n",
      "  File \"models/download-ggml.py\", line 16, in download_model\n",
      "    hh.hf_hub_download(repo_id=MODELS_REPO, filename=f'{model_name}/{filename}', repo_type='model', revision='main', local_dir='.', local_dir_use_symlinks=False)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py\", line 1291, in hf_hub_download\n",
      "    raise LocalEntryNotFoundError(\n",
      "huggingface_hub.utils._errors.LocalEntryNotFoundError: Connection error, and we cannot find the requested files in the disk cache. Please try again or make sure your Internet connection is on.\n",
      "Traceback (most recent call last):\n",
      "  File \"models/download-ggml.py\", line 35, in <module>\n",
      "    args.func(args)\n",
      "  File \"models/download-ggml.py\", line 16, in download_model\n",
      "    hh.hf_hub_download(repo_id=MODELS_REPO, filename=f'{model_name}/{filename}', repo_type='model', revision='main', local_dir='.', local_dir_use_symlinks=False)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/file_download.py\", line 1291, in hf_hub_download\n",
      "    raise LocalEntryNotFoundError(\n",
      "huggingface_hub.utils._errors.LocalEntryNotFoundError: Connection error, and we cannot find the requested files in the disk cache. Please try again or make sure your Internet connection is on.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# python3 models/download-ggml.py list_models\n",
    "!python models/download-ggml.py download all-MiniLM-L6-v2 q4_0\n",
    "!python models/download-ggml.py download all-MiniLM-L6-v2 f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘build’: File exists\n",
      "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "-- x86 detected\n",
      "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "-- x86 detected\n",
      "-- Linux detected\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /root/autodl-tmp/bert.cpp/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target ggml\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml.dir/ggml.c.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking C shared library libggml.so\u001b[0m\n",
      "[ 50%] Built target ggml\n",
      "\u001b[35m\u001b[1mScanning dependencies of target bert\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/bert.dir/bert.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libbert.so\u001b[0m\n",
      "[100%] Built target bert\n"
     ]
    }
   ],
   "source": [
    "!mkdir build\n",
    "os.chdir('build')\n",
    "!cmake .. -DBUILD_SHARED_LIBS=ON -DCMAKE_BUILD_TYPE=Release\n",
    "!make\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: loading model from 'models/all-MiniLM-L6-v2/ggml-model-f16.bin' - please wait ...\n",
      "bert_load_from_file: failed to open 'models/all-MiniLM-L6-v2/ggml-model-f16.bin'\n"
     ]
    }
   ],
   "source": [
    "!python examples/sample_dylib.py models/all-MiniLM-L6-v2/ggml-model-f16.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!./build/bin/server -m models/all-MiniLM-L6-v2/ggml-model-q4_0.bin --port 8085"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
